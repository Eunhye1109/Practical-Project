{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "EogwM4gSJMXV"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "1P6B_qR8OpaCD3o5sHv2Jykv0XJ1W9vVz",
      "authorship_tag": "ABX9TyMyYncDBvyk8jWCVM6o8VHA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eunhye1109/Practical-Project/blob/EH/250722_NLP_PDF_%EC%9A%94%EC%95%BD%ED%85%8C%EC%8A%A4%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01. finBERTëª¨ë¸ ì‹¤í—˜"
      ],
      "metadata": {
        "id": "599tDIoGBeWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "âœ… ì „ì²´ íë¦„ ê°œìš”\n",
        "- ëª©í‘œ:\n",
        "ì§€ì •ëœ í´ë” ë‚´ PDF ì‚¬ì—…ë³´ê³ ì„œë“¤ì„ FinBERT ê¸°ë°˜ ë¬¸ì¥ ê°ì„± ë¶„ì„ ë° ìš”ì•½\n",
        "\n",
        "- í´ë” ê²½ë¡œ:\n",
        "/content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ\n",
        "\n",
        "- ì‚¬ìš© ëª¨ë¸:\n",
        "FinBERT (ê°ì„± ë¶„ì„) + ì¶”ê°€ë¡œ Huggingface summarization ëª¨ë¸ (bart, t5 ë“±)\n",
        "\n"
      ],
      "metadata": {
        "id": "DVwM6CXd8v_-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zkk43GzR8vXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KolHaX2l-CAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Google Drive ë§ˆìš´íŠ¸"
      ],
      "metadata": {
        "id": "OwXuoPwT-CVf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "collapsed": true,
        "id": "xroWvmlW7_4Y",
        "outputId": "a69d5d59-8ff7-4d82-a901-88df6539a127"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-589980250.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: PDF í´ë” ê²½ë¡œ ì§€ì • ë° íŒŒì¼ ë¦¬ìŠ¤íŠ¸ í™•ë³´"
      ],
      "metadata": {
        "id": "9QjDJb-h-E9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# ì •í™•í•œ í´ë” ê²½ë¡œ\n",
        "pdf_dir = \"/content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ\"\n",
        "\n",
        "# í´ë” ì¡´ì¬ í™•ì¸\n",
        "if not os.path.exists(pdf_dir):\n",
        "    raise FileNotFoundError(f\"í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_dir}\")\n",
        "\n",
        "# PDF íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘\n",
        "pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith('.pdf')]\n",
        "\n",
        "# ë¦¬ìŠ¤íŠ¸ í™•ì¸\n",
        "print(f\"âœ… ì´ PDF íŒŒì¼ ìˆ˜: {len(pdf_files)}\")\n",
        "for f in pdf_files[:5]:\n",
        "    print(\"ğŸ“„\", f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQfWFfhG8KWe",
        "outputId": "8371fd05-1b36-4688-9774-b2b291181d95"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì´ PDF íŒŒì¼ ìˆ˜: 3005\n",
            "ğŸ“„ /content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ/á„ƒá…¢á„Œá…®á„‹á…µá„‹á…¦á†«á„á…µ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf\n",
            "ğŸ“„ /content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ/á„ƒá…¥á„á…¦á„á…³á„‚á…©á†¯á„…á…©á„Œá…µ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf\n",
            "ğŸ“„ /content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ/á„Šá…µá„‹á…¡á†º á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf\n",
            "ğŸ“„ /content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ/á„ƒá…©á†¼á„‰á…¥á†¼á„Œá…¦á„‹á…£á†¨ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf\n",
            "ğŸ“„ /content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ/á„€á…ªá†¼á„ƒá…©á†¼á„’á…¦á†¯á„‰á…³á„‡á…¡á„‹á…µá„‹á…© á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qdPLHyJL950G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: PyMuPDFë¡œ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ"
      ],
      "metadata": {
        "id": "xa378S_a-Jv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q PyMuPDF\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "gobgcDP3-MnL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: FinBERT ëª¨ë¸ ë¡œë“œ ë° finbert_pipleline ì •ì˜"
      ],
      "metadata": {
        "id": "mkBMMMsW-1n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
        "\n",
        "# FinBERT ëª¨ë¸ ë¡œë“œ\n",
        "tokenizer = BertTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
        "\n",
        "# ê°ì„± ë¶„ì„ íŒŒì´í”„ë¼ì¸ ìƒì„±\n",
        "finbert_pipeline = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU3KKaNT-8Pw",
        "outputId": "289fa288-cbb8-4ef0-9207-c353fc6dbfe1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: ê°ì„± ë¶„ì„ í•¨ìˆ˜ ì •ì˜\n",
        "\n"
      ],
      "metadata": {
        "id": "ar9jWLrI-PkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def analyze_sentiment(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    results = []\n",
        "    for sentence in sentences:\n",
        "        if len(sentence.strip()) >= 30:  # ë„ˆë¬´ ì§§ì€ ë¬¸ì¥ì€ ì œì™¸\n",
        "            sentiment = finbert_pipeline(sentence)[0]\n",
        "            results.append((sentence, sentiment['label'], sentiment['score']))\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "P4BFqbHh-RCb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r4kuNMK5-SL1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: ì²« PDF íŒŒì¼ ë¶„ì„ ì‹¤í–‰"
      ],
      "metadata": {
        "id": "rQIOX7P--TYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Punkt ê´€ë ¨ ì „ì²´ í† í¬ë‚˜ì´ì € ì„¸íŠ¸ ì¬ì„¤ì¹˜\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('tokenizers/punkt')\n",
        "nltk.download('tokenizers/punkt/english.pickle')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPnbgj8M-eYR",
        "outputId": "473cd7ed-8016-4756-a061-1be50aadb172"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Error loading tokenizers/punkt: Package 'tokenizers/punkt'\n",
            "[nltk_data]     not found in index\n",
            "[nltk_data] Error loading tokenizers/punkt/english.pickle: Package\n",
            "[nltk_data]     'tokenizers/punkt/english.pickle' not found in index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ì˜ˆì‹œìš©: ì²« ë²ˆì§¸ PDF íŒŒì¼ ì„ íƒ\n",
        "sample_pdf = pdf_files[0]\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "pdf_text = extract_text_from_pdf(sample_pdf)\n",
        "\n",
        "# ê°ì„± ë¶„ì„ ì‹¤í–‰\n",
        "results = analyze_sentiment(pdf_text)\n",
        "\n",
        "# ê²°ê³¼ ì§‘ê³„\n",
        "pos = [r for r in results if r[1] == 'positive']\n",
        "neg = [r for r in results if r[1] == 'negative']\n",
        "neu = [r for r in results if r[1] == 'neutral']\n",
        "\n",
        "# ìš”ì•½ ì¶œë ¥\n",
        "print(f\"\\nğŸ“˜ ë¶„ì„ ëŒ€ìƒ: {os.path.basename(sample_pdf)}\")\n",
        "print(f\"ğŸŸ¢ ê¸ì •: {len(pos)} | ğŸ”´ ë¶€ì •: {len(neg)} | âšª ì¤‘ë¦½: {len(neu)}\")\n",
        "\n",
        "print(\"\\nğŸ“Œ ëŒ€í‘œ ê¸ì • ë¬¸ì¥:\")\n",
        "for s in pos[:3]: print(\" -\", s[0])\n",
        "\n",
        "print(\"\\nğŸ“Œ ëŒ€í‘œ ë¶€ì • ë¬¸ì¥:\")\n",
        "for s in neg[:3]: print(\" -\", s[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VHWsAp8-T5F",
        "outputId": "f7bf7b86-c58e-4d78-cb3f-e1c3f1c9c364"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“˜ ë¶„ì„ ëŒ€ìƒ: á„ƒá…¢á„Œá…®á„‹á…µá„‹á…¦á†«á„á…µ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf\n",
            "ğŸŸ¢ ê¸ì •: 0 | ğŸ”´ ë¶€ì •: 0 | âšª ì¤‘ë¦½: 0\n",
            "\n",
            "ğŸ“Œ ëŒ€í‘œ ê¸ì • ë¬¸ì¥:\n",
            "\n",
            "ğŸ“Œ ëŒ€í‘œ ë¶€ì • ë¬¸ì¥:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract pdf2image\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "\n",
        "# OCRë¡œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "def extract_text_ocr(pdf_path):\n",
        "    pages = convert_from_path(pdf_path, dpi=300)\n",
        "    text = \"\"\n",
        "    for page in pages:\n",
        "        text += pytesseract.image_to_string(page, lang='eng+kor')  # í•œê¸€ë„ ê°€ëŠ¥í•˜ê²Œ\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ay6aoCUj-U4l",
        "outputId": "29c6c159-d7ca-46db-b0f2-b3c1dba1c2b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.11/dist-packages (1.17.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (25.0)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " print(pdf_text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmcmkHAf_OXs",
        "outputId": "a08fa984-f960-41c8-a053-c0e3a8c8a023"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª©                 ì°¨\n",
            "ì‚¬ì—…ë³´ê³ ì„œ ì œì¶œ ê¸°í•œ ì—°ì¥ ì‹ ê³ ì„œ.............................................................................................................1\n",
            "ì‚¬ì—…ë³´ê³ ì„œ ì œì¶œ ê¸°í•œ ì—°ì¥ ì‹ ê³ .................................................................................................................2\n",
            " \n",
            "ì‚¬ì—…ë³´ê³ ì„œ ì œì¶œ ê¸°í•œ ì—°ì¥ ì‹ ê³ ì„œ\n",
            " \n",
            " \n",
            " \n",
            " \n",
            "                                    ì œ 35 ê¸° \n",
            " \n",
            "2024ë…„ 01ì›” 01ì¼\n",
            "ë¶€í„°\n",
            "2024ë…„ 12ì›” 31ì¼\n",
            "ê¹Œì§€\n",
            "ê¸ˆìœµìœ„ì›íšŒ\n",
            "í•œêµ­ê±°ë˜ì†Œ ê·€ì¤‘\n",
            "2025 ë…„  3 ì›”   21 ì¼\n",
            "íšŒ      ì‚¬      ëª… :\n",
            "ëŒ€ì£¼ì´ì—”í‹° ì£¼ì‹íšŒì‚¬\n",
            "ëŒ€   í‘œ    ì´   ì‚¬ :\n",
            "í™©ê´‘ìˆ˜, ë°•ì£¼ë´‰\n",
            "ë³¸  ì   ì†Œ  ì¬  ì§€ :\n",
            "ì¸ì²œ ì¤‘êµ¬\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RDYa1ElBAINx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 02. PDF ì´ìŠˆ => BART ìš”ì•½ ëª¨ë¸ ì‚¬ìš©\n",
        "\n",
        "PDFë¼ finBERT ì•ˆë¨"
      ],
      "metadata": {
        "id": "MzJXQs0sAIsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1. ì„¤ì¹˜\n",
        "!pip install -q PyMuPDF transformers\n",
        "\n",
        "# STEP 2. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "xLiKSvVl_R6s"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3. BART ìš”ì•½ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n"
      ],
      "metadata": {
        "id": "Wt23JgTpADTA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4. ìš”ì•½ í•¨ìˆ˜ ì •ì˜ (ê¸´ í…ìŠ¤íŠ¸ ë¶„í• )\n",
        "def bart_chunked_summarize(text, chunk_size=1000, max_chunks=5):\n",
        "    from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "    # ì „ì²˜ë¦¬: ì¤„ë°”ê¿ˆ, ì ì„  ì œê±°\n",
        "    clean_text = text.replace('\\n', ' ').replace('Â·', '.').replace('â–ª', '-').strip()\n",
        "    sentences = clean_text.split('. ')  # ë¬¸ì¥ ë‹¨ìœ„ ë‚˜ëˆ„ê¸°\n",
        "\n",
        "    # chunk ìë¥´ê¸°\n",
        "    chunks = []\n",
        "    chunk = \"\"\n",
        "    for sentence in sentences:\n",
        "        if len(chunk) + len(sentence) < chunk_size:\n",
        "            chunk += sentence + '. '\n",
        "        else:\n",
        "            chunks.append(chunk.strip())\n",
        "            chunk = sentence + '. '\n",
        "        if len(chunks) >= max_chunks:\n",
        "            break\n",
        "    if chunk and len(chunks) < max_chunks:\n",
        "        chunks.append(chunk.strip())\n",
        "\n",
        "    # ê° chunk ìš”ì•½\n",
        "    summaries = []\n",
        "    for i, c in enumerate(chunks):\n",
        "        inputs = tokenizer([c], max_length=1024, return_tensors='pt', truncation=True)\n",
        "        summary_ids = model.generate(\n",
        "            inputs['input_ids'],\n",
        "            max_length=150,\n",
        "            min_length=40,\n",
        "            length_penalty=2.0,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        summaries.append(f\"ìš”ì•½ {i+1}: {summary}\")\n",
        "\n",
        "    return '\\n\\n'.join(summaries)\n"
      ],
      "metadata": {
        "id": "d9betDYIADsA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5. ê²½ë¡œ ì§€ì •í•˜ê³  ì‹¤í–‰\n",
        "# PDF ê²½ë¡œ ì…ë ¥\n",
        "pdf_path = \"/content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ/ê°•ì›ëœë“œ ì‚¬ì—…ë³´ê³ ì„œ (2024.12).pdf\"\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "text = extract_text_from_pdf(pdf_path)\n",
        "print(\"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ, ê¸¸ì´:\", len(text))\n",
        "\n",
        "# ìš”ì•½ ì‹¤í–‰\n",
        "if len(text.strip()) < 100:\n",
        "    print(\"âš ï¸ PDF ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ìš”ì•½ ìƒëµ.\")\n",
        "else:\n",
        "    summary = bart_chunked_summarize(text)\n",
        "    print(\"ğŸ“˜ ìš”ì•½ ê²°ê³¼:\\n\")\n",
        "    print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fnQVzruADuo",
        "outputId": "aa90fea0-27f1-4356-d074-0133915c7769"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ, ê¸¸ì´: 334914\n",
            "ğŸ“˜ ìš”ì•½ ê²°ê³¼:\n",
            "\n",
            "ìš”ì•½ 1: 1. I.   íšŒì‚¬ì˜ ê°œìš”............................................................................................................................................................................................................3 1. Â Â  Â   Â â€œ  ê³    ì„œ......................................................................................................................................4 3. â€œI.â€   â€œ â€ â€œâ€™â€â€œIâ€™m sorry, Iâ€™ve got to go.â€™ â€œ â€œ I.Â â€ I. â€˜â€‰â€™  â€‰â€‰ â€œWhatâ€™s wrong with this picture?â€\n",
            "\n",
            "ìš”ì•½ 2: 1.  Â  Â â€œ Â Â â€˜ ê°œìš”â€™,   â€œ   â€â€, â€œâ€™â€  â€˜â€™  â€â€™ â€œ,â€ â€˜, â€ â€™, â€™â€™. 2.  â€‰â€. â€œ. â€,  â€šâ€,. â€œÂ â€‰â€œ, â€‰, â€˜.â€™,. â€‰. â€‰,. â€.â€‰.â€ , â€œ;. â€™. â€˜;.â€šâ€™ , â€‰., â€‰;.\n",
            "\n",
            "ìš”ì•½ 3: ìœ„í—˜   Â â€™ê´€í•œ   â€˜â€™  â€œâ€  â€™â€™ â€™,  â€â€™â€, â€˜,â€™, â€œ,â€ â€˜;. â€,  â€â€˜, â€.â€™,.â€. â€™.â€,.â€™. â€˜. â€‰â€™Â â€˜â€œâ€™;.â€‰â€., â€œ. â€œ;.Â â€; â€œ:â€Â â€œ, â€‰, â€šâ€: â€œ., â€,. â€;\n",
            "\n",
            "ìš”ì•½ 4: ì—° í¬ê´„   Â â€œ  íšŒê³„â€   â€œâ€ (â€œâ€‰â€)  â€‰â€‰ â€œ  â€â€ â€œÂ â€™â€™ (â€â€™) (â€˜â€™ â€) â€œ â€œ,â€Â â€, â€,â€™, â€˜â€.â€™.â€\n",
            "\n",
            "ìš”ì•½ 5: ê¸ˆ   Â â€œï¿½ Â Â â€‰â€ (   â€˜â€™ (  â€œâ€) (â€œâ€™â€™) ( â€œÂ â€ â€œ, â€, â€™â€,  â€‰â€™, â€œ.â€ ) (â€˜â€â€™), â€â€œ,â€  â€šâ€™. â€œ â€ (â€™'â€™). â€. â€ â€™ â€™.â€™ â€,. â€˜. â€™,. â€., â€˜, â€˜;. â€˜,. â€™., â€œ;. 'â€.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 6. ì „ì²˜ë¦¬\n",
        "\n",
        "def clean_report_text(text):\n",
        "    # ì¤„ë°”ê¿ˆ ì œê±° ë° ì ì„  ì œê±°\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = text.replace('..............................................................................................', '')\n",
        "    # ê¸°í˜¸ ì •ë¦¬\n",
        "    for symbol in ['â€œ', 'â€', 'â€˜', 'â€™', 'â€¢', 'â–ª', 'Â·', 'â€³', \"'\", '\"']:\n",
        "        text = text.replace(symbol, '')\n",
        "    # ì—¬ëŸ¬ ê³µë°± ì œê±°\n",
        "    import re\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "C5Df3DxaADw4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#STEP 7. ì˜ë¯¸ ìˆëŠ” ë³¸ë¬¸ë§Œ ì¶”ì¶œ\n",
        "def extract_meaningful_section(text, keyword=\"ê°œìš”\"):\n",
        "    start = text.find(keyword)\n",
        "    if start == -1:\n",
        "        return text[:3000]  # ëª» ì°¾ìœ¼ë©´ ì•ë¶€ë¶„ ì¼ë¶€ë¼ë„ ì‚¬ìš©\n",
        "    else:\n",
        "        return text[start:start+5000]  # í•´ë‹¹ í‚¤ì›Œë“œë¶€í„° 5000ì ë¶„ëŸ‰ë§Œ ì‚¬ìš©\n"
      ],
      "metadata": {
        "id": "wivUkgNGADzP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text = extract_text_from_pdf(pdf_path)\n",
        "cleaned = clean_report_text(raw_text)\n",
        "meaningful = extract_meaningful_section(cleaned)\n",
        "summary = bart_chunked_summarize(meaningful, chunk_size=1000, max_chunks=3)\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkW8qV4XAD5P",
        "outputId": "e234ba6e-064e-4b35-fa11-22876940a147"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ìš”ì•½ 1: 1.  Â  Â â€˜   íšŒ  ê°œ Â ìš” Â 1.2. II.  â€˜ â€™ â€˜â€™   â€™â€™ 1.3. III. â€˜.â€™ 2. â€œâ€™â€ 1.4. IV.\n",
            "\n",
            "ìš”ì•½ 2: 1. Â    Â â€˜í˜„ê¸‰  íšŒê³„  ê¸ˆ  í•œ Â Â â€‰â€‰ â€˜â€˜â€â€™   â€œâ€™â€ (â€œâ€) (â€™)â€™ (â€˜)â€ â€™â€™ â€â€)(â€™, â€˜, â€, â€™) â€. â€ â€œ (â€), â€‰â€,  â€‰ â€œ, â€œ.â€.\n",
            "\n",
            "ìš”ì•½ 3: ê¸°íƒ€   Â â€˜â€˜  â€™   â€˜â€™ (â€˜) (â€™â€™) (  â€™â€) ( â€˜,â€™ â€™, â€˜), â€˜ â€™ â€˜.â€™ ) (â€â€™,â€, â€â€˜, â€œ, â€™.â€ ) ( â€™), â€™,.â€™ , â€˜;â€™,. â€˜,.â€,. â€™;. â€˜,'â€™.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9lwixRUoCD47"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 03. GPT APIë¥¼ í™œìš©í•œ ìë™í™” íŒŒì´í”„ë¼ì¸"
      ],
      "metadata": {
        "id": "BST1B6mqDtr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ìµœì‹  OpenAI SDK (v1.x) ê¸°ì¤€ PDF ë‹¤ì¤‘ ìš”ì•½ ìë™í™” ì½”ë“œ\n",
        "# - GPT-3.5-turbo ì‚¬ìš©\n",
        "# - ì‚¬ì—… ë³´ê³ ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ì•½ 10ì¤„ ì´ë‚´ë¡œ ìš”ì•½\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "from tqdm import tqdm\n",
        "import openai\n",
        "\n",
        "# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (v1.x ë¬¸ë²•)\n",
        "client = openai.OpenAI(api_key=\"\")  # ì—¬ê¸°ì— ë³¸ì¸ì˜ API í‚¤ ì…ë ¥\n",
        "\n",
        "# âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜\n",
        "def extract_text(pdf_path):\n",
        "    text = \"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# âœ… í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ì¤„ë°”ê¿ˆ ì œê±°, ê¸°í˜¸ ì •ë¦¬ ë“±)\n",
        "def clean_text(text):\n",
        "    import re\n",
        "    text = text.replace('\\n', ' ')\n",
        "    text = re.sub(r'[â€œâ€â€˜â€™â€¢â–ªÂ·â€³]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# âœ… ì‚¬ì—… ê°œìš” ìœ„ì£¼ í…ìŠ¤íŠ¸ ì¼ë¶€ë§Œ ì¶”ì¶œ\n",
        "def extract_section(text, keyword=\"II. ì‚¬ì—…ì˜ ë‚´ìš©\"):\n",
        "    start = text.find(keyword)\n",
        "    return text[start:start+5000] if start != -1 else text[:3000]\n",
        "\n",
        "# âœ… GPT ìš”ì•½ í•¨ìˆ˜ (ìµœì‹  ë²„ì „)\n",
        "def gpt_summary(prompt):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.3,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# âœ… PDF í•˜ë‚˜ ìš”ì•½ ì‹¤í–‰ í•¨ìˆ˜\n",
        "def summarize_file(pdf_path):\n",
        "    text = extract_text(pdf_path)\n",
        "    cleaned = clean_text(text)\n",
        "    section = extract_section(cleaned)\n",
        "    prompt = f\"ë‹¤ìŒì€ ì‚¬ì—…ë³´ê³ ì„œì˜ í•µì‹¬ ë‚´ìš©ì…ë‹ˆë‹¤. ì•½ 10ì¤„ ì´ë‚´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”:\\n\\n{section}\"\n",
        "    return gpt_summary(prompt)\n",
        "\n",
        "# âœ… í´ë” ë‚´ max_files ê°œìˆ˜ë§Œí¼ PDF ìˆœíšŒ ìš”ì•½ ì‹¤í–‰\n",
        "def batch_summarize(input_dir, output_dir, max_files=20):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    files = [f for f in os.listdir(input_dir) if f.endswith(\".pdf\")][:max_files]  # âœ¨ ì•ì—ì„œ 20ê°œë§Œ\n",
        "\n",
        "    for pdf_file in tqdm(files):\n",
        "        pdf_path = os.path.join(input_dir, pdf_file)\n",
        "        try:\n",
        "            summary = summarize_file(pdf_path)\n",
        "            with open(os.path.join(output_dir, pdf_file.replace(\".pdf\", \".txt\")), \"w\") as f:\n",
        "                f.write(summary)\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {pdf_file} - {e}\")\n",
        "\n",
        "# âœ… ì‹¤í–‰ ì˜ˆì‹œ (ê²½ë¡œë§Œ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)\n",
        "input_dir = \"/content/drive/MyDrive/2. á„á…±á„‹á…¥á†¸ á„‡á…®á„‹á…¥á†¸/7. SWá„€á…¢á„‡á…¡á†¯á„Œá…¡á„€á…ªá„Œá…¥á†¼/3. á„‰á…µá†¯á„Œá…¥á†«á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/[á„‰á…µá†¯á„Œá…¥á†«] á„Œá…¢á„†á…® á„€á…ªá†«á„…á…§á†« á„ƒá…¦á„‹á…µá„á…¥_á„’á…©á„‰á…¥á†¼ á„á…µá†·/PDF á„‰á…¡á„‹á…¥á†¸ á„‡á…©á„€á…©á„‰á…¥\"\n",
        "output_dir = \"/content/drive/MyDrive/2. á„á…±á„‹á…¥á†¸ á„‡á…®á„‹á…¥á†¸/7. SWá„€á…¢á„‡á…¡á†¯á„Œá…¡á„€á…ªá„Œá…¥á†¼/3. á„‰á…µá†¯á„Œá…¥á†«á„‘á…³á„…á…©á„Œá…¦á†¨á„á…³/[á„‰á…µá†¯á„Œá…¥á†«] á„Œá…¢á„†á…® á„€á…ªá†«á„…á…§á†« á„ƒá…¦á„‹á…µá„á…¥_á„’á…©á„‰á…¥á†¼ á„á…µá†·/0722_PDF summaries\"\n",
        "batch_summarize(input_dir, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXCgRpv8DyYG",
        "outputId": "0094dd92-49df-4bea-824b-74b2684e72e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|â–Œ         | 1/20 [00:02<00:46,  2.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„ƒá…¢á„Œá…®á„‹á…µá„‹á…¦á†«á„á…µ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|â–ˆ         | 2/20 [00:04<00:41,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„ƒá…¥á„á…¦á„á…³á„‚á…©á†¯á„…á…©á„Œá…µ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|â–ˆâ–Œ        | 3/20 [00:06<00:39,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„Šá…µá„‹á…¡á†º á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|â–ˆâ–ˆ        | 4/20 [00:09<00:37,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„ƒá…©á†¼á„‰á…¥á†¼á„Œá…¦á„‹á…£á†¨ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:11<00:34,  2.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„€á…ªá†¼á„ƒá…©á†¼á„’á…¦á†¯á„‰á…³á„‡á…¡á„‹á…µá„‹á…© á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:13<00:32,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‡á…¡á„‹á…µá„‹á…©á„á…¦á†« á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:16<00:29,  2.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: KBá„Œá…¦30á„’á…©á„‰á…³á„‘á…¢á†¨ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:18<00:27,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„Œá…µá†«á„ƒá…© [á„€á…µá„Œá…¢á„Œá…¥á†¼á„Œá…¥á†¼]á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:20<00:25,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„ƒá…¢á„’á…¡á†«á„‹á…£á†¨á„‘á…®á†· á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:23<00:23,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‹á…µá„…á…¦á†· á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:25<00:21,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‹á…µá„‹á…¦á†·á„á…¦á†¨ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:27<00:18,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‹á…§á†¼á„…á…µá†·á„‹á…¯á†«á„‰á…©á„‘á…³á„á…³á„…á…¢á†¸ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:30<00:16,  2.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„’á…¡á†«á„‰á…©á†¯á„…á…©á„Œá…µá„‰á…³á„á…µá†¨á„‰á…³ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:32<00:14,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‹á…¡á†«á„€á…®á†¨á„‹á…£á†¨á„‘á…®á†· á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:34<00:11,  2.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‰á…¡á†·á„‡á…®á„á…©á„€á…¥á†« á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:37<00:09,  2.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‰á…¥á„‹á…®á†¯á„‡á…¡á„‹á…µá„‹á…©á„‰á…µá„‰á…³ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:39<00:06,  2.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‰á…¦á„á…©á„‘á…µá„‹á…¡ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥á„Œá…¦á„á…®á†¯á„€á…µá„’á…¡á†«á„‹á…§á†«á„Œá…¡á†¼á„‰á…µá†«á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:41<00:04,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‰á…¥á†«á„‰á…£á„‹á…µá†«á„‘á…®á„ƒá…³ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:44<00:02,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: SBIá„‹á…µá†«á„‡á…¦á„‰á…³á„á…³á„†á…¥á†«á„á…³ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:46<00:00,  2.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âŒ ì˜¤ë¥˜ ë°œìƒ: á„‹á…²á„‹á…¡á†«á„á…¡á„Œá…¦12á„’á…©á„‰á…³á„‘á…¢á†¨ á„‰á…¡á„‹á…¥á†¸á„‡á…©á„€á…©á„‰á…¥ (2024.12).pdf - Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vELFlBiDz2a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zf8kPhDBG1WA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KoBART Summarization"
      ],
      "metadata": {
        "id": "EogwM4gSJMXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ëª¨ë¸ëª…: digit82/kobart-summarization\n",
        "\n",
        "- ì¥ì :\n",
        "\n",
        "  - ë¬¸ì„œí˜• ê¸´ í…ìŠ¤íŠ¸ë„ ìš”ì•½ ê°€ëŠ¥\n",
        "\n",
        "  - HuggingFace ê¸°ë°˜ì´ë¯€ë¡œ ë¡œì»¬ ë˜ëŠ” Colabì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥\n",
        "\n",
        "  - í•œêµ­ì–´ í•™ìŠµ ìµœì í™”ë¨ (AIHub ë‰´ìŠ¤ ìš”ì•½ ë°ì´í„° ê¸°ë°˜)"
      ],
      "metadata": {
        "id": "4mZ7Y2g9Nk8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sentencepiece\n",
        "!pip install pdfplumber\n",
        "!pip install transformers sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGD43QDCG5fS",
        "outputId": "7260378e-2b97-49a6-e66f-55e8deabbf76"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRvXVtMnG83W",
        "outputId": "344dd0ea-5008-4ee2-c86b-b66120e11740"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.7)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.2.1)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Google Drive ì—°ë™ ë° PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "\n",
        "import pdfplumber\n",
        "from google.colab import drive\n",
        "\n",
        "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# PDF ê²½ë¡œ\n",
        "pdf_path = \"/content/drive/MyDrive/2. ì·¨ì—… ë¶€ì—…/7. SWê°œë°œìê³¼ì •/3. ì‹¤ì „í”„ë¡œì íŠ¸/[ì‹¤ì „] ì¬ë¬´ ê´€ë ¨ ë°ì´í„°_í˜¸ì„± íŒ€/PDF ì‚¬ì—… ë³´ê³ ì„œ/ê°•ì›ëœë“œ ì‚¬ì—…ë³´ê³ ì„œ (2024.12).pdf\"\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
        "all_text = \"\"\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    for page in pdf.pages:\n",
        "        all_text += page.extract_text() + \"\\n\"\n",
        "\n",
        "print(\"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ì „ì²´ ê¸¸ì´:\", len(all_text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeyHPuuuN5oq",
        "outputId": "fea7ffd9-cc96-4b27-f249-70a2749b63da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ. ì „ì²´ ê¸¸ì´: 326924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. KoBART ìš”ì•½ ëª¨ë¸ ë¡œë”©\n",
        "\n",
        "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
        "\n",
        "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6cKynveN7UY",
        "outputId": "39f20e16-327e-4fce-8c50-644e18d0ea44"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels will be overwritten to 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tl2WFWrOOPZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ ìš”ì•½ ì‹¤í–‰\n",
        "\n",
        "import re\n",
        "\n",
        "# ì „ì²˜ë¦¬: ê³µë°± ì •ë¦¬\n",
        "clean_text = re.sub(r'\\s+', ' ', all_text)\n",
        "\n",
        "# ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ìš”ì•½\n",
        "window_size = 3000\n",
        "step_size = 2500\n",
        "summaries = []\n",
        "\n",
        "for i in range(0, len(clean_text), step_size):\n",
        "    chunk = clean_text[i:i+window_size]\n",
        "    input_ids = tokenizer.encode(chunk, return_tensors='pt', max_length=1024, truncation=True)\n",
        "    summary_ids = model.generate(input_ids, max_length=200, min_length=60, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
        "    summary_text = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    summaries.append(summary_text)\n",
        "    print(f\"ğŸ”¹ {i//step_size + 1}ë²ˆì§¸ ìš”ì•½ ì™„ë£Œ\")\n",
        "\n",
        "# ì „ì²´ ìš”ì•½ ì—°ê²°\n",
        "final_summary = \"\\n\\n\".join(summaries)\n",
        "print(\"ğŸ“˜ ì „ì²´ ì¢…í•© ìš”ì•½ ê²°ê³¼:\\n\")\n",
        "print(final_summary)\n"
      ],
      "metadata": {
        "id": "P4JpltcnN7hH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GUXhCnxnN7jW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lXt_SnS5N7le"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1vcLkZavN7nd"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9o574q-RN7pg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1aatwQEQN7rQ"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}
