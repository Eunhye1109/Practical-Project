{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y5Lek2yu6g02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ë”ë¯¸ë°ì´í„° + í…ŒìŠ¤íŠ¸"
      ],
      "metadata": {
        "id": "l3Hor-AK1LQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ì„¸íŒ…ê°’(ê±°ì˜ defaultê°’)"
      ],
      "metadata": {
        "id": "yCkSgiw16kZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# file: test_gpt_graph_summary.py\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import os\n",
        "import json\n",
        "from statistics import mean, pstdev\n",
        "from typing import List, Dict, Any, Optional\n",
        "import numpy as np\n",
        "\n",
        "# -----------------------------\n",
        "# OpenAI (optional)\n",
        "# -----------------------------\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    _OPENAI_AVAILABLE = True\n",
        "except Exception:\n",
        "    OpenAI = None\n",
        "    _OPENAI_AVAILABLE = False\n",
        "\n",
        "# -----------------------------\n",
        "# ë¶„ì„ í•¨ìˆ˜\n",
        "# -----------------------------\n",
        "def _linear_fit(values: List[float]) -> (float, float):\n",
        "    x = np.arange(len(values), dtype=float)\n",
        "    y = np.array(values, dtype=float)\n",
        "    coef = float(np.polyfit(x, y, 1)[0])\n",
        "    yhat = np.poly1d(np.polyfit(x, y, 1))(x)\n",
        "    ss_res = float(np.sum((y - yhat) ** 2))\n",
        "    ss_tot = float(np.sum((y - np.mean(y)) ** 2))\n",
        "    r2 = 0.0 if ss_tot == 0 else 1.0 - (ss_res / ss_tot)\n",
        "    return coef, r2\n",
        "\n",
        "def _volatility(values: List[float]) -> float:\n",
        "    if len(values) < 2:\n",
        "        return 0.0\n",
        "    mu = mean(values)\n",
        "    if mu == 0:\n",
        "        return 0.0\n",
        "    sd = pstdev(values)\n",
        "    return float(sd / mu)\n",
        "\n",
        "def _zscore_anomalies(labels: List[str], values: List[float], thresh: float = 2.0) -> List[Dict[str, Any]]:\n",
        "    if len(values) < 2:\n",
        "        return []\n",
        "    mu = mean(values)\n",
        "    sd = pstdev(values)\n",
        "    if sd == 0:\n",
        "        return []\n",
        "    out = []\n",
        "    for lab, val in zip(labels, values):\n",
        "        z = (val - mu) / sd\n",
        "        if abs(z) >= thresh:\n",
        "            out.append({\"label\": lab, \"value\": float(val), \"zscore\": float(z), \"note\": \"í”¼í¬\" if z > 0 else \"ì €ì \"})\n",
        "    return out\n",
        "\n",
        "def _trend_label_and_score(slope: float, r2: float, vol: float) -> (str, float):\n",
        "    if abs(slope) < 1e-8:\n",
        "        base = \"flat\"\n",
        "        score = max(0.0, 1 - vol)\n",
        "    else:\n",
        "        base = \"up\" if slope > 0 else \"down\"\n",
        "        score = min(1.0, max(0.0, (abs(slope) / (abs(slope) + 1)) * 0.6 + r2 * 0.4))\n",
        "    if vol >= 0.15 and base == \"flat\":\n",
        "        base = \"volatile\"\n",
        "        score *= 0.5\n",
        "    return base, float(round(score, 3))\n",
        "\n",
        "def analyze(labels: List[str], values: List[float]) -> Dict[str, Any]:\n",
        "    slope, r2 = _linear_fit(values)\n",
        "    vol = _volatility(values)\n",
        "    anoms = _zscore_anomalies(labels, values, 2.0)\n",
        "    tlabel, tscore = _trend_label_and_score(slope, r2, vol)\n",
        "    return {\n",
        "        \"slope\": float(slope),\n",
        "        \"r2\": float(round(r2, 4)),\n",
        "        \"volatility\": float(round(vol, 4)),\n",
        "        \"trend\": tlabel,\n",
        "        \"trend_score\": float(round(tscore, 3)),\n",
        "        \"anomalies\": anoms,\n",
        "    }\n",
        "\n",
        "# -----------------------------\n",
        "# GPT ìš”ì•½\n",
        "# -----------------------------\n",
        "def gpt_summary(metric_name: str, labels: List[str], values: List[float],\n",
        "                company: str, unit: str, freq: str, ana: Dict[str, Any]) -> Optional[str]:\n",
        "    # âœ… GPT í‚¤ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€\n",
        "    if not OPENAI_API_KEY or not _OPENAI_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    # âœ… í”„ë¡¬í”„íŠ¸ì— ë„£ì„ ì¶”ê°€ ì§€í‘œë“¤ ê³„ì‚°(ìµœê·¼ ë³€í™”, í”¼í¬/ì €ì )\n",
        "    last_label = labels[-1]\n",
        "    last_val = float(values[-1])\n",
        "    prev_val = float(values[-2]) if len(values) >= 2 else last_val\n",
        "    delta_abs = last_val - prev_val\n",
        "    delta_pct = 0.0 if prev_val == 0 else (delta_abs / prev_val) * 100.0\n",
        "\n",
        "    peak_idx = int(np.argmax(values))\n",
        "    trough_idx = int(np.argmin(values))\n",
        "    peak_label, peak_val = labels[peak_idx], float(values[peak_idx])\n",
        "    trough_label, trough_val = labels[trough_idx], float(values[trough_idx])\n",
        "\n",
        "    # âœ… í”„ë¡¬í”„íŠ¸ ë³¸ë¬¸ (ë¶„ì„ì¹˜ + ì»¨í…ìŠ¤íŠ¸ ë°˜ì˜)\n",
        "    prompt = f\"\"\"ë‹¤ìŒ ì‹œê³„ì—´ ê·¸ë˜í”„ë¥¼ í•œêµ­ì–´ë¡œ ì¤‘í•™ìƒë„ ì•Œì•„ë³¼ ìˆ˜ ìˆì„ ë§Œí¼ ì‰½ê³  ê°„ë‹¨í•˜ê²Œ ìš”ì•½í•´ì¤˜.\n",
        "\n",
        "[ì»¨í…ìŠ¤íŠ¸]\n",
        "- íšŒì‚¬: {company or \"í•´ë‹¹ ê¸°ì—…\"}\n",
        "- ì§€í‘œ: {metric_name}\n",
        "- ë‹¨ìœ„: {unit or \"\"}\n",
        "- ë¹ˆë„: {freq or \"\"}\n",
        "\n",
        "[ë°ì´í„°]\n",
        "- ë¼ë²¨: {labels}\n",
        "- ê°’: {[float(v) for v in values]}\n",
        "\n",
        "[ì‚¬ì „ ë¶„ì„ì¹˜]\n",
        "- ì„ í˜• ê¸°ìš¸ê¸°: {ana[\"slope\"]:.4f}\n",
        "- ê²°ì •ê³„ìˆ˜ R^2: {ana[\"r2\"]:.2f}\n",
        "- ë³€ë™ì„±: {ana[\"volatility\"]:.2f}\n",
        "- ì´ìƒì¹˜ ê°œìˆ˜: {len(ana[\"anomalies\"])}\n",
        "\n",
        "[í¬ì¸íŠ¸]\n",
        "- ìµœê·¼ê°’: {last_label} = {last_val}\n",
        "- ì§ì „ ëŒ€ë¹„ ë³€í™”: {delta_abs:+.2f} ({delta_pct:+.2f}%)\n",
        "- ìµœê³ ì¹˜: {peak_label} = {peak_val}\n",
        "- ìµœì €ì¹˜: {trough_label} = {trough_val}\n",
        "\n",
        "[ì§€ì‹œ]\n",
        "1) ì „ë°˜ì ì¸ íë¦„ê³¼ ìµœê·¼ ë³€í™” ì¤‘ì‹¬ìœ¼ë¡œ **2~3ë¬¸ì¥**ìœ¼ë¡œ ì¨ë¼.\n",
        "2) ìˆ«ì ë¹„êµëŠ” 1~2ê°œë§Œ í•µì‹¬ë§Œ ì¨ë¼(ì˜ˆ: \"ìµœê·¼ ë¶„ê¸° -3%\").\n",
        "3) ê³¼ëŒ€í•´ì„ ê¸ˆì§€. ë¶ˆí™•ì‹¤í•˜ë©´ 'ê°€ëŠ¥ì„±/ì¶”ì •'ìœ¼ë¡œ í‘œí˜„.\n",
        "4) ì´ëª¨ì§€Â·ê³¼ì¥ í‘œí˜„Â·ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ê¸ˆì§€.\n",
        "5) ì¤‘í•™ìƒ ìˆ˜ì¤€ì˜ ì‰¬ìš´ ë§ë¡œ, ì´ íë¦„ê³¼ ë³€í™”ê°€ ë¬´ì—‡ì„ ì˜ë¯¸í•˜ëŠ”ì§€ ê°„ë‹¨í•œ í•´ì„ì„ ë§ë¶™ì¼ ê²ƒ.\n",
        "\"\"\"\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ì°¨íŠ¸ ì•„ë˜ ë“¤ì–´ê°ˆ ì‰½ê³  ê°ê´€ì ì¸ í•œêµ­ì–´ ìš”ì•½ì„ ì‘ì„±í•œë‹¤.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=320,\n",
        "    )\n",
        "    return (resp.choices[0].message.content or \"\").strip()\n"
      ],
      "metadata": {
        "id": "kiGxm-kq1KmF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ë³€ê²½ê°’(í˜„ì¬ ë”ë¯¸ë°ì´í„° ë„£ì€ ìƒíƒœ)"
      ],
      "metadata": {
        "id": "FPNvxd-D6qTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
        "# -----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # ë”ë¯¸ ë°ì´í„°\n",
        "    labels = [\"2024-Q1\", \"2024-Q2\", \"2024-Q3\", \"2024-Q4\", \"2025-Q1\"] # â˜…â˜…â˜…labels ê°’ ë³€ê²½!!!\n",
        "    values = [120, 135, 142, 160, 155] # â˜…â˜…â˜… values ê°’ ë³€ê²½!!!\n",
        "\n",
        "    ana = analyze(labels, values)\n",
        "\n",
        "    # âœ… ì‹¤ì œ ê°’ìœ¼ë¡œ ì „ë‹¬(ì¤‘ê´„í˜¸ í”Œë ˆì´ìŠ¤í™€ë” ì œê±°)\n",
        "    company = \"ì‚¼ì„±ì „ì\"\n",
        "    unit = \"ì–µ ì›\"\n",
        "    freq = \"quarterly\"\n",
        "\n",
        "    summary_text = gpt_summary(\"ë§¤ì¶œì•¡\", labels, values, company, unit, freq, ana)\n",
        "    if not summary_text:\n",
        "        dir_kor = {\"up\": \"ìƒìŠ¹\", \"down\": \"í•˜ë½\", \"flat\": \"íš¡ë³´\", \"volatile\": \"ë³€ë™ì„± í™•ëŒ€\"}[ana[\"trend\"]]\n",
        "        summary_text = f\"ì „ë°˜ì ìœ¼ë¡œ {dir_kor} íë¦„ì´ ê´€ì°°ë©ë‹ˆë‹¤(RÂ²={ana['r2']:.2f}).\"\n",
        "        if ana[\"anomalies\"]:\n",
        "            a = ana[\"anomalies\"][-1]\n",
        "            summary_text += f\" {a['label']} ì‹œì ì— ì´ìƒì¹˜(ê°’ {a['value']})ê°€ ìˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "    print(\"\\nğŸ“Š ë¶„ì„ ê²°ê³¼\")\n",
        "    print(json.dumps(ana, ensure_ascii=False, indent=2))\n",
        "    print(\"\\nğŸ“ ìš”ì•½ ê²°ê³¼\")\n",
        "    print(summary_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8r9oRap3QLH",
        "outputId": "d15dd887-000b-48c5-afeb-ac756b7bd15b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Š ë¶„ì„ ê²°ê³¼\n",
            "{\n",
            "  \"slope\": 9.49999999999999,\n",
            "  \"r2\": 0.8803,\n",
            "  \"volatility\": 0.1006,\n",
            "  \"trend\": \"up\",\n",
            "  \"trend_score\": 0.895,\n",
            "  \"anomalies\": []\n",
            "}\n",
            "\n",
            "ğŸ“ ìš”ì•½ ê²°ê³¼\n",
            "ì‚¼ì„±ì „ìì˜ ë§¤ì¶œì•¡ì€ 2024ë…„ 1ë¶„ê¸° 120ì–µ ì›ì—ì„œ ì‹œì‘í•´ 2024ë…„ 4ë¶„ê¸°ì—ëŠ” 160ì–µ ì›ìœ¼ë¡œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ 2025ë…„ 1ë¶„ê¸°ì—ëŠ” 155ì–µ ì›ìœ¼ë¡œ ì¤„ì–´ë“¤ì–´ ìµœê·¼ ë¶„ê¸°ì—ì„œ -3%ì˜ ê°ì†Œê°€ ìˆì—ˆìŠµë‹ˆë‹¤. ì´ ë³€í™”ëŠ” ë§¤ì¶œì´ ì „ë°˜ì ìœ¼ë¡œ ìƒìŠ¹í•˜ë‹¤ê°€ ìµœê·¼ì— ì•½ê°„ ì¤„ì–´ë“  ê²ƒì„ ë³´ì—¬ì£¼ë©°, ì•ìœ¼ë¡œì˜ ë§¤ì¶œ íë¦„ì— ëŒ€í•œ ì£¼ì˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_eq0tCld6svp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bmVbNM6a1Kjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "idbG9BGW1Khd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}