# utils/column_matcher.py
import json
import os
import torch
from sentence_transformers import SentenceTransformer, util

class ColumnMatcher:
    def __init__(self, standard_columns, manual_map=None, cache_path="column_cache.json", min_similarity=0.80):
        self.standard_columns = standard_columns
        self.manual_map = manual_map or {}
        self.model = SentenceTransformer("snunlp/KR-SBERT-V40K-klueNLI-augSTS")
        self.standard_embeddings = self.model.encode(self.standard_columns, convert_to_tensor=True)
        self.min_similarity = min_similarity

        self.cache_path = cache_path
        self.match_cache = self._load_cache()

    def _load_cache(self):
        if os.path.exists(self.cache_path):
            with open(self.cache_path, "r", encoding="utf-8") as f:
                return json.load(f)
        return {}

    def _save_cache(self):
        with open(self.cache_path, "w", encoding="utf-8") as f:
            json.dump(self.match_cache, f, ensure_ascii=False, indent=2)

    def match(self, raw_column: str, candidates=None, corp_name=None, verbose=True) -> str | None:
        # 1. ìˆ˜ë™ ë§¤í•‘
        if raw_column in self.manual_map:
            return self.manual_map[raw_column]

        # 2. ìºì‹œ ê²€ìƒ‰
        if corp_name:
            cached = self.match_cache.get(raw_column, {}).get(corp_name)
            if cached and cached["score"] >= self.min_similarity:
                if verbose:
                    print(f"[ğŸ§ ] ìºì‹œ ë§¤í•‘: '{raw_column}' â†’ '{cached['matched']}' (score: {cached['score']:.2f})")
                return cached["matched"]

        # 3. í›„ë³´ ì œí•œ
        if candidates:
            standard_subset = [col for col in self.standard_columns if col in candidates]
            standard_embeddings = self.model.encode(standard_subset, convert_to_tensor=True)
        else:
            standard_subset = self.standard_columns
            standard_embeddings = self.standard_embeddings

        # 4. ìœ ì‚¬ë„ ê³„ì‚°
        raw_embedding = self.model.encode(raw_column, convert_to_tensor=True)
        cos_scores = util.cos_sim(raw_embedding, standard_embeddings)[0]
        best_idx = torch.argmax(cos_scores).item()
        best_score = cos_scores[best_idx].item()
        best_match = standard_subset[best_idx]

        if verbose:
            print(f"[ğŸ”] '{raw_column}' â†’ '{best_match}' (score: {best_score:.4f})")

        # 5. ê¸°ì¤€ ì´ìƒë§Œ ë°˜í™˜
        if best_score >= self.min_similarity:
            if corp_name:
                self.match_cache.setdefault(raw_column, {})[corp_name] = {
                    "matched": best_match,
                    "score": best_score
                }
                self._save_cache()
            return best_match
        else:
            print(f"[âš ï¸] '{raw_column}' ìœ ì‚¬ë„ {best_score:.2f} â†’ ê¸°ì¤€ ë¯¸ë‹¬ë¡œ ë§¤ì¹­ ì‹¤íŒ¨")
            return None

def batch_match_columns(
+        self,
+        targets: list[str],
+        raw_candidates: list[str],
+        corp_name: str
+    ) -> dict[str, str]:
+        """
+        ê¸°ì—…(corp_name) ë‹¨ìœ„ë¡œ, í‘œì¤€ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸(targets)ë¥¼
+        í•œ ë²ˆì— raw_candidatesì—ì„œ ë§¤í•‘í•˜ê³  ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤.
+        """
+        mapping: dict[str,str] = {}
+        for std_col in targets:
+            # ì´ë¯¸ ìºì‹œì— ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°
+            cached = self.match_cache.get(std_col, {}).get(corp_name)
+            if cached and cached["score"] >= self.min_similarity:
+                mapping[std_col] = cached["matched"]
+                continue
+
+            # ë§¤ì¹­ ì‹œë„ (verbose=Falseë¡œ ë¡œê·¸ ìµœì†Œí™”)
+            matched = self.match(std_col, candidates=raw_candidates, corp_name=corp_name, verbose=False)
+            if matched:
+                mapping[std_col] = matched
+        return mapping